{{- if .Values.application.ai.enabled }}
image:
  repository: {{ printf "%s/%s" (coalesce .Values.container.ollama.registry .Values.container.default.registry) (.Values.container.ollama.repository) | quote }}
  tag: {{ .Values.container.ollama.tag | quote }}
  pullPolicy: "Always"

imagePullSecrets:
  - name: {{ .Values.container.default.imagePullSecret | quote }}

# We need to specify the mountPath to point
# to a directory we have access to as non-root user.
ollama:
  models:
    pull:
      - llama3.2
    run:
      - llama3.2
  mountPath: "/home/ollama/.ollama"
  gpu:
    enabled: {{ .Values.ai.selfhost.gpu.enabled | default false }}
    {{- if .Values.ai.selfhost.gpu.enabled }}
    type: {{ .Values.ai.selfhost.gpu.type | default "nvidia" | quote }}
    number: {{ .Values.ai.selfhost.gpu.number | default 1 }}
    {{- if .Values.ai.selfhost.gpu.mig }}
    mig:
      enabled: {{ .Values.ai.selfhost.gpu.mig.enabled | default false }}
      {{- if .Values.ai.selfhost.gpu.mig.devices }}
      devices:
        {{- toYaml .Values.ai.selfhost.gpu.mig.devices | nindent 8 }}
      {{- end }}
    {{- end }}
    {{- end }}


# We need to specify the environment variable HOME used by Ollama to point
# to a directory we have access to as non-root user. This needs to be the
# directory the .ollama file above is mounted in.
extraEnv:
  - name: HOME
    value: "/home/ollama"

resources:
  {{- if .Values.resource.ollama }}
  {{- toYaml .Values.resource.ollama | nindent 2 }}
  {{- else }}
  limits:
    memory: "4Gi"
    cpu:  "750m"
  requests:
    memory: "2Gi"
    cpu: "400m"
  {{- end }}

persistentVolume:
  enabled: true
  size: 15Gi
  accessModes:
    - ReadWriteOnce
  storageClass: {{ coalesce .Values.pvc.ollama.storageClass .Values.pvc.default.storageClass | quote }}

{{- end }}
